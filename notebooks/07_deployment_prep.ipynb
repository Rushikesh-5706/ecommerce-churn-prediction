{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment Preparation & Verification\n",
    "\n",
    "This notebook simulates the deployment environment and verifies the application logic.\n",
    "\n",
    "## Objectives:\n",
    "- Verify `app/streamlit_app.py` dependencies\n",
    "- Test model loading in a simulated production environment\n",
    "- Generate sample predictions\n",
    "- Check `submission.json` validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T09:20:21.395601Z",
     "iopub.status.busy": "2026-02-11T09:20:21.395504Z",
     "iopub.status.idle": "2026-02-11T09:20:21.646526Z",
     "shell.execute_reply": "2026-02-11T09:20:21.646151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Environment check passed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"✓ Environment check passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Verify Model Existence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T09:20:21.648059Z",
     "iopub.status.busy": "2026-02-11T09:20:21.647939Z",
     "iopub.status.idle": "2026-02-11T09:20:21.650549Z",
     "shell.execute_reply": "2026-02-11T09:20:21.650149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Found: ../models/best_model.pkl\n",
      "✓ Found: ../data/processed/feature_names.json\n",
      "✓ Found: ../models/scaler.pkl\n",
      "✓ Found: ../data/processed/feature_info.json\n",
      "✓ Found: ../submission.json\n",
      "\n",
      "✓ All deployment files present\n"
     ]
    }
   ],
   "source": [
    "required_files = [\n",
    "    '../models/best_model.pkl',\n",
    "    '../data/processed/feature_names.json',\n",
    "    '../models/scaler.pkl',\n",
    "    '../data/processed/feature_info.json',\n",
    "    '../submission.json'\n",
    "]\n",
    "\n",
    "missing = []\n",
    "for f in required_files:\n",
    "    if not os.path.exists(f):\n",
    "        print(f\"❌ Missing: {f}\")\n",
    "        missing.append(f)\n",
    "    else:\n",
    "        print(f\"✓ Found: {f}\")\n",
    "\n",
    "if missing:\n",
    "    print(\"\\nCRITICAL: Missing deployment files!\")\n",
    "else:\n",
    "    print(\"\\n✓ All deployment files present\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simulate Prediction Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T09:20:21.651729Z",
     "iopub.status.busy": "2026-02-11T09:20:21.651640Z",
     "iopub.status.idle": "2026-02-11T09:20:22.343133Z",
     "shell.execute_reply": "2026-02-11T09:20:22.342734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: XGBClassifier\n",
      "Expected Features: 39\n",
      "\n",
      "Prediction: 1\n",
      "Probability: [0.26207888 0.7379211 ]\n",
      "✓ Inference test passed\n"
     ]
    }
   ],
   "source": [
    "# Load model artifacts\n",
    "model = joblib.load('../models/best_model.pkl')\n",
    "scaler = joblib.load('../models/scaler.pkl')\n",
    "with open('../data/processed/feature_names.json', 'r') as f:\n",
    "    features = json.load(f)['feature_names']\n",
    "\n",
    "print(f\"Model: {type(model).__name__}\")\n",
    "print(f\"Expected Features: {len(features)}\")\n",
    "\n",
    "# Create dummy input\n",
    "dummy_input = pd.DataFrame(np.random.rand(1, len(features)), columns=features)\n",
    "dummy_scaled = scaler.transform(dummy_input)\n",
    "\n",
    "# Predict\n",
    "try:\n",
    "    pred = model.predict(dummy_scaled)\n",
    "    prob = model.predict_proba(dummy_scaled)\n",
    "    \n",
    "    print(f\"\\nPrediction: {pred[0]}\")\n",
    "    print(f\"Probability: {prob[0]}\")\n",
    "    print(\"✓ Inference test passed\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Inference failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Validate Submission JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T09:20:22.344416Z",
     "iopub.status.busy": "2026-02-11T09:20:22.344298Z",
     "iopub.status.idle": "2026-02-11T09:20:22.346781Z",
     "shell.execute_reply": "2026-02-11T09:20:22.346484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"student_info\": {\n",
      "        \"name\": \"Rushikesh\",\n",
      "        \"email\": \"rushikeshkunisetty@gmail.com\",\n",
      "        \"student_id\": \"23MH1A4930\",\n",
      "        \"submission_date\": \"2026-02-10\"\n",
      "    },\n",
      "    \"repository\": {\n",
      "        \"github_url\": \"https://github.com/Rushikesh-5706/Customer-Churn-Prediction-System\",\n",
      "        \"commit_hash\": \"latest-commit-hash\"\n",
      "    },\n",
      "    \"deployment\": {\n",
      "        \"live_url\": \"https://customer-churn-prediction.streamlit.app\",\n",
      "        \"platform\": \"Streamlit Cloud\",\n",
      "        \"deployment_date\": \"2026-02-10\",\n",
      "        \"status\": \"Ready for Deployment\"\n",
      "    },\n",
      "    \"dataset\": {\n",
      "        \"source\": \"UCI Machine Learning Repository\",\n",
      "        \"url\": \"http://archive.ics.uci.edu/ml/datasets/Online+Retail+II\",\n",
      "        \"original_rows\": 525461,\n",
      "        \"cleaned_rows\": 342273,\n",
      "        \"final_customers\": 3213\n",
      "    },\n",
      "    \"models\": {\n",
      "        \"models_trained\": [\n",
      "            \"Logistic Regression\",\n",
      "            \"Decision Tree\",\n",
      "            \"Random Forest\",\n",
      "            \"Gradient Boosting\",\n",
      "            \"Neural Network\"\n",
      "        ],\n",
      "        \"best_model\": \"Random Forest\",\n",
      "        \"best_model_metrics\": {\n",
      "            \"accuracy\": 0.6884,\n",
      "            \"precision\": 0.4692,\n",
      "            \"recall\": 0.5259,\n",
      "            \"f1_score\": 0.4959,\n",
      "            \"roc_auc\": 0.7267\n",
      "        }\n",
      "    },\n",
      "    \"completion_status\": {\n",
      "        \"phase1_business_understanding\": true,\n",
      "        \"phase2_data_acquisition\": true,\n",
      "        \"phase3_data_cleaning\": true,\n",
      "        \"phase4_feature_engineering\": true,\n",
      "        \"phase5_eda\": true,\n",
      "        \"phase6_modeling\": true,\n",
      "        \"phase7_evaluation\": true,\n",
      "        \"phase8_deployment\": true,\n",
      "        \"phase9_documentation\": true,\n",
      "        \"phase10_code_quality\": true\n",
      "    },\n",
      "    \"key_learnings\": [\n",
      "        \"Implementation of SMOTE increased ROC-AUC by 0.01-0.02, proving effective for 42% churn imbalance\",\n",
      "        \"Feature engineering (RFM + Temporal) was more critical than model selection\",\n",
      "        \"Strict temporal splitting (283/45 days) prevents data leakage relative to random splits\"\n",
      "    ],\n",
      "    \"challenges_faced\": [\n",
      "        \"High natural churn rate (41.92%) made achieving 0.75 ROC-AUC difficult (best: 0.7307)\",\n",
      "        \"Precision-Recall trade-off required prioritizing Recall (67%) to capture more churners\",\n",
      "        \"Optimizing observation window to balance sufficient churn events vs. data freshness\"\n",
      "    ]\n",
      "}\n",
      "\n",
      "⚠️  ROC-AUC matches requirement?\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open('../submission.json', 'r') as f:\n",
    "        submission = json.load(f)\n",
    "\n",
    "    print(json.dumps(submission, indent=4))\n",
    "\n",
    "    # Validation checks\n",
    "    if submission.get('roc_auc', 0) < 0.75:\n",
    "        print(\"\\n⚠️  ROC-AUC matches requirement?\")\n",
    "    else:\n",
    "        print(\"\\n✓ ROC-AUC meets requirement\")\n",
    "except FileNotFoundError:\n",
    "    print(\"⚠️  submission.json not found yet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
